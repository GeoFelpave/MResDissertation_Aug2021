{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This notebook was created to capture the data wrangling process for all the datasets. This will include the commands used in NCO and other libraries, but it will only run code written in Python.\n",
    "\n",
    "---\n",
    "\n",
    " - Author:          \n",
    "                    Luis F Patino Velasquez - MA\n",
    " - Date:            \n",
    "                    Jun 2020\n",
    " - Version:         \n",
    "                    1.0\n",
    " - Notes:            \n",
    "                    files used in this notebook are in format netCDF\n",
    " - Jupyter version: \n",
    "                    jupyter core     : 4.7.1\n",
    "                    jupyter-notebook : 6.4.0\n",
    "                    qtconsole        : 5.1.1\n",
    "                    ipython          : 7.25.0\n",
    "                    ipykernel        : 6.0.3\n",
    "                    jupyter client   : 6.1.12\n",
    "                    jupyter lab      : 3.0.16\n",
    "                    nbconvert        : 6.1.0\n",
    "                    ipywidgets       : 7.6.3\n",
    "                    nbformat         : 5.1.3\n",
    "                    traitlets        : 5.0.5\n",
    " - Python version:  \n",
    "                    3.8.5 \n",
    "\n",
    "---\n",
    "\n",
    "## Main considerations\n",
    "\n",
    "* The main time period considered for all datasets is 2001 - 2019, this is based on GPM-IMERG data\n",
    "\n",
    "## Setting Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Global vars\n",
    "sep = ('''------------\\n------------''')\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5\n",
    "\n",
    "ERA5 data was downloaded as 24 hourly steps (0, 1, 2, 3, 4,..,23) for each calendar day starting from Jan 1 to Dec 31 of each considered year.\n",
    "\n",
    "ECMWF state here https://confluence.ecmwf.int/display/CKB/ERA5%3A+How+to+calculate+daily+total+precipitation that daily total precipitation must be calculated by accumulating precipitation for e.g. Jan 1, 1979 by summing the steps 1, 2,...,23 of Jan 1 AND step 0 of Jan 2. It means that the step 0 of Jan 1, 1979 is not included in calculation of the total precipitation for that day. For calculation of total precipitation for Jan 2, 1979 we use also the steps 1, 2, 3,...,23 of that day plus step 0 of Jan 3 and so on.\n",
    "\n",
    "* The following NCO code was used to create daily total precipitation `cdo -b F64 daysum -shifttime,-1hour era5_fileTwo.nc era5_prcp_daysum_nco_2000-2010.nc`\n",
    "* The following NCO code was used to change from m to mm `cdo mulc,1000 era5_prcp_daysum_nco_2000-2010.nc era5_prcp_daysum_mm_nco_2000-2010.nc`\n",
    "* The following NCO code was used to change the units in the tp variable `ncatted -O -a units,tp,m,c,\"mm d-1\" in.nc`\n",
    "\n",
    "*After creating the daily precipitation files the following line was used to add the standard_name to the tp variable needed for xclim*\n",
    "\n",
    "* `ncatted -O -a standard_name,tp,c,c,\"total_precipitation\" in_DAY.nc`\n",
    "\n",
    "## Creating the daily total precipitation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/era_copernicus_uk/')\n",
    "\n",
    "# Create list of daily total precipitation files \n",
    "annual_fls = fldr_src.glob('**/era5_copernicus_prcp_daysum_mm*')\n",
    "# annual_fls = fldr_src.glob('**/era5_prcp_daysum_nco*')\n",
    "\n",
    "# Create final file\n",
    "for era_fl in annual_fls:\n",
    "    if era_fl.name.split('_')[5][:4] != '2000':\n",
    "        yr_fst = era_fl.name.split('_')[5][:4] + '-01-01'\n",
    "        yr_lst = era_fl.name.split('_')[5][5:9] + '-12-31'\n",
    "        filename = 'era5_copernicus_DAY_prcp_' + era_fl.name.split('_')[5]\n",
    "    else:\n",
    "        yr_fst = '2001-01-01'\n",
    "        yr_lst = era_fl.name.split('_')[5][5:9] + '-12-31'\n",
    "        filename = 'era5_copernicus_DAY_prcp_' + '2001' + '-' + era_fl.name.split('_')[5][5:9] + '.nc'\n",
    "    \n",
    "    # Open data and drop the first timestep of the input data as per the ECMWF statement\n",
    "    dataset = xr.open_dataset(era_fl, decode_timedelta=False)\n",
    "    dataset_annual = dataset.sel(time=slice(yr_fst, yr_lst))\n",
    "\n",
    "    # Saving file with annual precipitations\n",
    "    annual_prcp = Path(fldr_src / filename)\n",
    "    print ('saving to ', annual_prcp)\n",
    "    dataset_annual.to_netcdf(path=annual_prcp)\n",
    "    print ('finished saving')\n",
    "    dataset.close()\n",
    "    \n",
    "print(sep)\n",
    "print('All done!! check files in {}'.format(fldr_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HadUK-Grid\n",
    "\n",
    "HadUK-Grid data was downloaded as monthly files for each calendar day starting from Jan 1 to Dec 31 of each considered year.\n",
    "\n",
    "* The following NCO code was used to change the units in the rainfall variable `ncatted -O -a units,rainfall,m,c,\"mm d-1\" in.nc`\n",
    "\n",
    "The line of code was run as part of a the follwing bash code:\n",
    "\n",
    "```\n",
    "#! /bin/bash\n",
    "\n",
    "FILES='folder path with files/*'\n",
    "for f in $FILES\n",
    "do\n",
    "\techo \"Processing $f\"\n",
    "    ncatted -O -a units,rainfall,m,c,\"mm d-1\" $f\n",
    "done\n",
    "\n",
    "```\n",
    "\n",
    "***HadUK-Grid files did not require any data wrangling using python***\n",
    "\n",
    "## Checking File downloaded correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/haduk_cedac_uk/')\n",
    "\n",
    "# Create list with files\n",
    "fls_lst = fldr_src.glob('**/*.nc')\n",
    "\n",
    "# Check to see if the file structure is correct - ie it opens using xarray\n",
    "arr_err = []\n",
    "for fl in fls_lst:\n",
    "    try:\n",
    "        dataset = xr.open_dataset(fl, decode_timedelta=False)\n",
    "        dataset.close()\n",
    "    except:\n",
    "        arr_err.append(fl)\n",
    "        print('Doing file: {}'.format(fl))\n",
    "\n",
    "if len(arr_err) == 0:\n",
    "    print('The files were downloaded correctly')\n",
    "else:\n",
    "    print ('The following files could not be opened: {}'.format(arr_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking output after units change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/haduk_cedac_uk/')\n",
    "# !ls {fldr_src}\n",
    "\n",
    "dataset = xr.open_dataset(Path(fldr_src / 'rainfall_hadukgrid_uk_5km_day_20020601-20020630.nc'), decode_timedelta=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPM-IMERG\n",
    "\n",
    "ERA5 data was downloaded as daily files for each calendar day starting from Jan 1 to Dec 31 of each considered year.\n",
    "\n",
    "* The following NCO code was used to change the units in the rainfall variable `ncatted -O -a units,rainfall,m,c,\"mm d-1\" in.nc`\n",
    "\n",
    "The change of units NCO code was run as part of a the follwing bash code:\n",
    "\n",
    "```\n",
    "#! /bin/bash\n",
    "\n",
    "FILES='folder path with files/*'\n",
    "for f in $FILES\n",
    "do\n",
    "\techo \"Processing $f\"\n",
    "    ncatted -O -a units,rainfall,m,c,\"mm d-1\" $f\n",
    "done\n",
    "\n",
    "```\n",
    "\n",
    "## Checking File downloaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/gpm_imerg_nasa_uk/')\n",
    "\n",
    "# Create list with files\n",
    "fls_lst = fldr_src.glob('**/*')\n",
    "\n",
    "# Check to see if the file structure is correct - ie it opens using xarray\n",
    "arr_err = []\n",
    "for fl in fls_lst:\n",
    "    try:\n",
    "        dataset = xr.open_dataset(fl, decode_timedelta=False)\n",
    "        dataset.close()\n",
    "    except:\n",
    "        arr_err.append(fl)\n",
    "        print('Doing file: {}'.format(fl))\n",
    "\n",
    "if len(arr_err) == 0:\n",
    "    print('The files were downloaded correctly')\n",
    "else:\n",
    "    print ('The following files could not be opened: {}'.format(arr_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking output after units change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/gpm_imerg_nasa_uk/')\n",
    "# !ls {fldr_src}\n",
    "\n",
    "dataset = xr.open_dataset(Path(fldr_src / '3B-DAY.MS.MRG.3IMERG.20001002-S000000-E235959.V06.nc4.nc4'), decode_timedelta=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify precipitation values for all files\n",
    "\n",
    "* All precipitation values under 1mm will be modified to Zero\n",
    "* This step is carried out using a batch file and over a copy of all the data modified in previous steps.\n",
    "* The following NCO command was in a copy (to avoid modifying the main datasets) all the files for HadUK-grid, IMERG and ERA5 `ncap2 -s 'where(precipitationCal <= 1.0) precipitationCal=0.0;' -O in.nc out.nc`\n",
    "\n",
    "```\n",
    "#! /bin/bash\n",
    "FILES='folder path with files/*'\n",
    "for f in $FILES\n",
    "do\n",
    "\techo \"Processing $f\"\n",
    "    # change variable name to match the one in the files\n",
    "    ncap2 -s 'where(precipitationCal < 1.0) precipitationCal=0.0;' -O $f $f\n",
    "done\n",
    "#! /bin/bash\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified HadUK-Grid from planar to geodesic coordenates\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    " <p style=\"color:black\"> <b>Caution: This should only be run BEFORE creating the indices datasets and AFTER making sure there are not values under 1mm in the rainfall variable</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is as follows:\n",
    "\n",
    "* All HadUK-Grid files are merge into one nc file - rainfall_hadukgrid_uk_5km_day_2001-2019.nc\n",
    "* The following variables need to be removed using NCO:\n",
    "    - `ncks -C -O -x -v projection_y_coordinate_bnds,projection_x_coordinate_bnds rainfall_hadukgrid_uk_5km_day_2001-2019.nc rainfall_hadukgrid_uk_5km_day_2001-2019_step1.nc`\n",
    "    - `ncks -C -x -v latitude,longitude,time_bnds rainfall_hadukgrid_uk_5km_day_2001-2019_step1.nc rainfall_hadukgrid_uk_5km_day_OSGB36_2001-2019.nc`\n",
    "    \n",
    "## Reproject data using rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "\n",
    "# Set directory to read and for outputs\n",
    "fldr_src = Path('/mnt/d/MRes_dataset/search_data/haduk_cedac_uk_xclim/')\n",
    "fldr_out = Path('/mnt/d/MRes_dataset/active_data/106_precp')\n",
    "\n",
    "# Create list with files\n",
    "fls_lst = fldr_src.glob('**/*.nc')\n",
    "\n",
    "# Read HadUK-Grid data and merge all into one file\n",
    "dataset_HADUK = xr.open_mfdataset(paths=fls_lst, combine='by_coords', parallel=True)\n",
    "dataset_HADUK.to_netcdf(Path(fldr_out / 'rainfall_hadukgrid_uk_5km_day_2001-2019.nc'))\n",
    "\n",
    "print('---------')\n",
    "print('Use NCO to modify the rainfall_hadukgrid_uk_5km_day_2001-2019.nc file before processiding to next step')\n",
    "print('---------')\n",
    "print('File saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting transformed dataset for Xclim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    " <p style=\"color:black\"> <b>Caution: Before running xclim the transformed data attribute need changing, so coordinates show as latitude and longitude</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read transformed file\n",
    "dsin = Dataset(Path(fldr_out/ 'rainfall_hadukgrid_uk_5km_day_WGS84_2001-2019.nc'))\n",
    "\n",
    "# Output file\n",
    "dsout = Dataset(Path(fldr_out / 'rainfall_hadukgrid_uk_5km_day_WGS84LatLon_2001-2019.nc'), mode='w',format='NETCDF3_CLASSIC')\n",
    "\n",
    "# Create dimensions\n",
    "for dimname,dim in f.dimensions.items():\n",
    "    dsout.createDimension(dimname,len(dim))\n",
    "\n",
    "# Copy variables\n",
    "# transform_mercator is dropped as it is needed.\n",
    "for v_name, varin in dsin.variables.items():\n",
    "    if v_name == 'x':\n",
    "        outVar = dsout.createVariable('longitude', varin.datatype, ('longitude',))\n",
    "        # Copy variable attributes\n",
    "        outVar.setncatts({k: varin.getncattr(k) for k in varin.ncattrs()})\n",
    "        outVar[:] = varin[:]\n",
    "    if v_name == 'y':\n",
    "        outVar = dsout.createVariable('latitude', varin.datatype, ('latitude',))\n",
    "        # Copy variable attributes\n",
    "        outVar.setncatts({k: varin.getncattr(k) for k in varin.ncattrs()})\n",
    "        outVar[:] = varin[:]\n",
    "    if v_name == 'rainfall':\n",
    "        outVar = dsout.createVariable(v_name, varin.datatype, ('time', 'latitude', 'longitude'))\n",
    "        # Copy variable attributes\n",
    "        outVar.setncatts({k: varin.getncattr(k) for k in varin.ncattrs()})\n",
    "        outVar[:] = varin[:]\n",
    "    if v_name == 'time':\n",
    "        outVar = dsout.createVariable(v_name, np.float64, varin.dimensions)\n",
    "        # Copy variable attributes\n",
    "        outVar.setncatts({k: varin.getncattr(k) for k in varin.ncattrs()})\n",
    "        outVar[:] = varin[:]\n",
    "\n",
    "# close the output file to\n",
    "dsout.close()\n",
    "\n",
    "print('---------')\n",
    "print('The transformed data is already to go')\n",
    "print('---------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
