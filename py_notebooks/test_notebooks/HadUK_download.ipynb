{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307f8e0d-a08f-4cfe-8673-8c1586d2bebf",
   "metadata": {},
   "source": [
    "# Donwloading GPM-IMERG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fad60e0-ed45-41fb-9b70-c1f0b7427ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'==============================================================================\\n\\n Title          :GPM_IMERG_download.ipynb\\n Description    :Download GPM IMERG data from Nasa server\\n Author         :LF Velasquez - MA\\n Date           :May 20 2021\\n Version        :1.0\\n Usage          :GPM_IMERG_download.ipynb\\n Notes          : \\n                - The user must have a earthdata account\\n                - This code is based on the code developed by Peter Smith, last modified by Srikanth Davu\\n                  https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+Python\\n python version :3.8.5\\n\\n=============================================================================='"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"==============================================================================\n",
    "\n",
    " Title          :HadUK_download.ipynb\n",
    " Description    :Download HadUK-Grid data from CEDA Archive \n",
    " Author         :LF Velasquez - MA\n",
    " Date           :July 02 2021\n",
    " Version        :1.0\n",
    " Usage          :HadUK_download.ipynb\n",
    " Notes          : \n",
    "                - The user must have a CEDA account\n",
    " python version :3.8.5\n",
    "\n",
    "==============================================================================\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc233f-4d37-4fe8-830a-53d12234c46c",
   "metadata": {},
   "source": [
    "**Importing Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98be0be9-48d7-4bad-9b92-d09231bb888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http.cookiejar import CookieJar\n",
    "# from urllib.parse import urlencode\n",
    "\n",
    "# import urllib.request as urllib2\n",
    "# import requests\n",
    "from pathlib import Path\n",
    "import wget\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7995a-ccfb-4acb-b05b-d48b43ac2eec",
   "metadata": {},
   "source": [
    "**Adding data directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ade66a-8da7-4744-a46e-12de5cc60957",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = Path('/mnt/d/MRes_dataset/search_data/haduk_cedac_uk/') # path for CEH data store data\n",
    "\n",
    "\n",
    "# uncomment below to check if it is the right path\n",
    "# !ls {FILEPATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b3f52-76d5-4daf-90b2-b8f1f87073ba",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35fda2dd-e3ac-4c47-8790-af4ce96012fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_download(data_url, file_2save):\n",
    "    result = requests.get(data_url)\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "        f = open(file_2save,'wb')\n",
    "        f.write(result.content)\n",
    "        f.close()\n",
    "        print('contents of URL written to: {} '.format(file_2save))\n",
    "    except:\n",
    "        print('requests.get() returned an error code: {}'.format(str(result.status_code)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222542bd-7d24-4ab1-a8a7-da18ada69325",
   "metadata": {},
   "source": [
    "**Set CEDA Archiveinformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5edf8c6d-aedd-41db-98ff-9de1c40747c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Credential\n",
    "\n",
    "# # CEDA Archive\n",
    "# username = \"geofelpave\"\n",
    "# password = \"wIU2qQgf9h4D0\"\n",
    "\n",
    "# # Create password manager for 401 response\n",
    "# password_manager = urllib2.HTTPPasswordMgrWithDefaultRealm()\n",
    "# password_manager.add_password(None, \"https://data.ceda.ac.uk/\", username, password) #Earthdata url\n",
    "# # password_manager.add_password(None, \"https://catalogue.ceh.ac.uk\", username, password) #CEH data store url\n",
    "\n",
    "# # Create cookie jar to store cookies. This will avoid having to authenticate user everytime data is requested\n",
    "# cookie_jar = CookieJar()\n",
    "\n",
    "# # Install handlers\n",
    "# opener = urllib2.build_opener(\n",
    "#     urllib2.HTTPBasicAuthHandler(password_manager),\n",
    "#     #urllib2.HTTPHandler(debuglevel=1),    # Uncomment these two lines to see\n",
    "#     #urllib2.HTTPSHandler(debuglevel=1),   # details of the requests/responses\n",
    "#     urllib2.HTTPCookieProcessor(cookie_jar))\n",
    "# urllib2.install_opener(opener)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42cfe11-7b80-4615-9e1d-eb9e952cf514",
   "metadata": {},
   "source": [
    "# Working with Earthdata data\n",
    "**Create list with dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff2a9e2-def3-4f24-848c-81d7d1914719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dates list ready to pass in URL\n",
    "\n",
    "# Set loop to go through years - from 2000 to 2019\n",
    "dates_lst = []\n",
    "year = 2000\n",
    "\n",
    "# create date objects\n",
    "begin_year = datetime(year, 1, 1)\n",
    "end_year = datetime(2019, 12, 31)\n",
    "next_year = begin_year\n",
    "\n",
    "while next_year <= end_year:\n",
    "    dates_lst.append(next_year)\n",
    "    next_year = next_year +  relativedelta(months=+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb43836-b46f-4e88-9011-7033f52972f2",
   "metadata": {},
   "source": [
    "**Working with the date list to request the data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd8e3e2-0674-4bef-b5c3-4d10b76f3ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dap.ceda.ac.uk/badc/ukmo-hadobs/data/insitu/MOHC/HadOBS/HadUK-Grid/v1.0.2.1/5km/rainfall/day/v20200731/rainfall_hadukgrid_uk_5km_day_20000101-20000131.nc\n",
      "requests.get() returned an error code: 500\n",
      "--------------\n",
      "--------------\n",
      "Check files here: /mnt/d/MRes_dataset/search_data/haduk_cedac_uk\n",
      "--------------\n",
      "--------------\n",
      "This is the URL to check\n"
     ]
    }
   ],
   "source": [
    "# set list for url that can be reached\n",
    "for fecha in dates_lst:\n",
    "    lst_day = calendar.monthrange(fecha.year, fecha.month)[1]\n",
    "    \n",
    "#     https://dap.ceda.ac.uk/badc/ukmo-hadobs/data/insitu/MOHC/HadOBS/HadUK-Grid/v1.0.2.1/5km/rainfall/day/v20200731/rainfall_hadukgrid_uk_5km_day_20191201-20191231.nc\n",
    "#     https://dap.ceda.ac.uk/badc/ukmo-hadobs/data/insitu/MOHC/HadOBS/HadUK-Grid/v1.0.2.1/5km/rainfall/day/v20200731/rainfall_hadukgrid_uk_5km_day_20000101-20000131.nc\n",
    "    \n",
    "    url_p1 = 'https://dap.ceda.ac.uk/badc/ukmo-hadobs/data/insitu/MOHC/HadOBS/HadUK-Grid/v1.0.2.1/5km/rainfall/day/v20200731/'\n",
    "    url_p2 = 'rainfall_hadukgrid_uk_5km_day_'\n",
    "    \n",
    "    # Use f-strings to get padded date and month\n",
    "    url = url_p1 + url_p2 + f\"{fecha:%Y%m%d}\" + '-' + f\"{fecha:%Y%m}\" + str(lst_day) + '.nc'\n",
    "    print(url)\n",
    "   \n",
    "    # Create file to save data in local drive\n",
    "    FILENAME = url_p2 + f\"{fecha:%Y%m%d}\" + '-' + f\"{fecha:%Y%m}\" + str(lst_day) + '.nc'\n",
    "    SAVEFILE = Path(FILEPATH / FILENAME)\n",
    "    \n",
    "    # Run request using function\n",
    "    SAVEFILE = Path(FILEPATH / FILENAME)\n",
    "#     print(SAVEFILE)\n",
    "    \n",
    "#     wget.download(url, str(SAVEFILE))\n",
    "    data_download(url, SAVEFILE)\n",
    "    break\n",
    "    \n",
    "print ('--------------')\n",
    "print ('--------------')\n",
    "print ('Check files here: {}'.format(FILEPATH ))\n",
    "print ('--------------')\n",
    "print ('--------------')\n",
    "print ('This is the URL to check')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea3d78-e134-41b5-b4c3-dc7f9aff123c",
   "metadata": {},
   "source": [
    "# Working with CEH datastore\n",
    "**Create list of years** (*The daily data is stored by year*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eaecf0b-3f89-4cdd-bf57-d40d60557157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n"
     ]
    }
   ],
   "source": [
    "# Create dates list ready to pass in URL\n",
    "# add relativedata module\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Set loop to go through years - from 2000 to 2019\n",
    "year_lst = []\n",
    "year = 2000\n",
    "\n",
    "# Create date objects\n",
    "begin_year = datetime.date(2000,1,1)\n",
    "end_year = datetime.date(2017, 12, 31)\n",
    "one_year = relativedelta(years=1)\n",
    "\n",
    "# Append year as a string to the year list\n",
    "next_year = begin_year\n",
    "while next_year <= end_year:\n",
    "    year_lst.append(f\"{next_year:%Y}\")\n",
    "    next_year += one_year\n",
    "print(year_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dc5e1-a0eb-4551-bf25-460fd25da9d6",
   "metadata": {},
   "source": [
    "**Working with the date list to request the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de1a73a-b568-4b4f-82dd-491297003630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://catalogue.ceh.ac.uk/datastore/eidchub/ee9ab43d-a4fe-4e73-afd5-cd4fc4c82556/GB/daily/CEH_GEAR_daily_GB_2000.nc\n",
      "contents of URL written to: /mnt/d/MRes_dataset/search_data/gear_ceh_uk/CEH_GEAR_daily_GB_2000.nc \n",
      "--------------\n",
      "--------------\n",
      "Check files here: /mnt/d/MRes_dataset/search_data/gear_ceh_uk\n",
      "--------------\n",
      "--------------\n",
      "This is the URL to check\n"
     ]
    }
   ],
   "source": [
    "# set list for url that can be reached\n",
    "for year in year_lst:\n",
    "    url_p1 = 'https://catalogue.ceh.ac.uk/datastore/eidchub/ee9ab43d-a4fe-4e73-afd5-cd4fc4c82556/GB/daily/CEH_GEAR_daily_GB_'\n",
    "\n",
    "    # Use f-strings to get padded date and month\n",
    "    url = url_p1 + year + '.nc'\n",
    "    print(url)\n",
    "    \n",
    "    # Create file to save data in local drive\n",
    "    FILENAME = 'CEH_GEAR_daily_GB_' + year + '.nc'\n",
    "    SAVEFILE = Path(FILEPATH / FILENAME)\n",
    "    \n",
    "    # Run request using function\n",
    "    data_download(url, SAVEFILE)\n",
    "    break\n",
    "    \n",
    "print ('--------------')\n",
    "print ('--------------')\n",
    "print ('Check files here: {}'.format(FILEPATH ))\n",
    "print ('--------------')\n",
    "print ('--------------')\n",
    "print ('This is the URL to check')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da2145-48c9-443b-833e-ba3c875b4110",
   "metadata": {},
   "source": [
    "## Data download check\n",
    "\n",
    "- The code below will only need to be run after doing the download of the data\n",
    "- The code checks the files downloaded against the files that are expected based on the years\n",
    "- If the file has not been downloaded, the code will try to download the code again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d4a08a-1244-496f-9752-f0ee0212e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing files in the folder \n",
      "\n",
      "Trying to download the files again\n",
      "--------------\n",
      "--------------\n",
      "All the files have been downloaded!\n",
      "--------------\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Create list of file names\n",
    "name_lst = []\n",
    "for date in dates_lst:\n",
    "    part1 = '3B-DAY.MS.MRG.3IMERG.'\n",
    "    part2 = '-S000000-E235959.V06.nc4.nc4'\n",
    "    file_name = part1 + f\"{date:%Y%m%d}\" + part2\n",
    "    name_lst.append(file_name)\n",
    "\n",
    "# Create list of file names in folder\n",
    "file_lst = []\n",
    "python_files = FILEPATH.glob('**/*.nc4') \n",
    "for pf in python_files:\n",
    "    file_lst.append(pf.parts[6])\n",
    "    \n",
    "# Compare the two list and get missing values\n",
    "# the main list is name_lst as it contains names of expected files\n",
    "missing = list(sorted(set(name_lst) - set(file_lst)))\n",
    "print ('There are {} missing files in the folder \\n'.format(len(missing)))\n",
    "\n",
    "# print ('--------------')\n",
    "# print ('--------------')\n",
    "print ('Trying to download the files again')\n",
    "# print ('--------------')\n",
    "# print ('--------------')\n",
    "\n",
    "# set list for url that can be reached\n",
    "'3B-DAY.MS.MRG.3IMERG.20000604-S000000-E235959.V06.nc4.nc4'\n",
    "\n",
    "if len(missing) > 0:\n",
    "    fd\n",
    "    url_toCheck = []\n",
    "    for file_name in missing:\n",
    "        url_p1 = 'https://gpm1.gesdisc.eosdis.nasa.gov/opendap/GPM_L3/GPM_3IMERGDF.06/'\n",
    "        url_p2 = file_name\n",
    "        url_p3 = '?precipitationCal[0:0][1709:1819][1389:1509],time_bnds[0:0][0:1],time,lon[1709:1819],lat[1389:1509]'\n",
    "\n",
    "        # Get year and month from the file name\n",
    "        year = file_name.split('.')[4][:4]\n",
    "        month = file_name.split('.')[4][:6][-2:]\n",
    "\n",
    "    #     build URL\n",
    "        url = url_p1 + year + '/' + month + '/' + file_name + url_p3\n",
    "        print(url)\n",
    "\n",
    "        # Create file to save data in local drive\n",
    "        FILENAME = file_name\n",
    "        SAVEFILE = Path(FILEPATH / FILENAME)\n",
    "\n",
    "        # Run request using function\n",
    "        data_nasa(url, SAVEFILE)\n",
    "\n",
    "    print ('--------------')\n",
    "    print ('--------------')\n",
    "    print ('Check files here: {}'.format(FILEPATH ))\n",
    "    print ('--------------')\n",
    "    print ('--------------')\n",
    "else:\n",
    "    print ('--------------')\n",
    "    print ('--------------')\n",
    "    print ('All the files have been downloaded!')\n",
    "    print ('--------------')\n",
    "    print ('--------------')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
